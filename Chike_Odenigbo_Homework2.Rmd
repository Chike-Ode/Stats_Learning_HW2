---
title: "Homework 2"
author: "Chike Odenigbo"
date: "November 6, 2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
#install.packages("knitr")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("ISLR")
#install.packages('rpart')
#install.packages("ipred")
#install.packages("randomForest")
#install.packages("adabag")
library(randomForest)
library(ipred)
library(ISLR)
library(rpart)
library(adabag)
set.seed(123)
```

```{r}
get_accuracy <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  accuracy = round((TP + TN) / sum(TP,FP,TN,FN), 2)
  return(accuracy)
}

get_classification_error_rate <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  classification_error_rate = round((FP + FN) / sum(TP,FP,TN,FN),2)
  return(classification_error_rate)
}

get_precision <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  precision = round(TP / (TP + FP), 2)
  return(precision)
}


get_sensitivity <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  sensitivity = round(TP / (TP + FN), 2)
  return(sensitivity)
}

get_specificity <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  specificity = round(TN / (TN + FP), 2)
  return(specificity)
}

get_f1_score <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  
  precision = round(TP / (TP + FP), 2)
  sensitivity = round(TP / (TP + FN), 2)
  f1_score = round((2 * precision * sensitivity) / (precision + sensitivity), 2)
  return(f1_score)
}

get_false_positive_rate <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  
  fpr = round(FP / (FP + TN), 2)
  return(fpr)
}

get_false_negative_rate <- function(predicted, actual){
  confusion_table = table(predicted, actual)
  TP = confusion_table[2,2]
  TN = confusion_table[1,1]
  FN = confusion_table[1,2]
  FP = confusion_table[2,1]
  
  fnr = round(FN / (FN + TP), 2)
  return(fnr)
}
```
## Section 1
### Question 1.1
Create a training set of 800 observations, and a test set containing the rest using the following code:
```{r}
# ```{r pressure, echo=FALSE}
n <- nrow(OJ)
set.seed(1234)
id.train=sample(1:n,size=800)
id.test=setdiff(1:n,id.train)
OJ$Purchase = as.factor(OJ$Purchase)
OJ$Store7 = as.factor(OJ$Store7)
as.data.frame(sapply(OJ,class))
OJ.train=OJ[id.train,-3]
OJ.test=OJ[id.test,-3]
```

### Question 1.2
Construct an unpruned classification tree to predict the variable purchase using the available predictors. Calculate the false positive rate, false negative rate and overall error rate of this tree on the test data (note: you can use your code from the previous assignment directly for this question).
```{r}
# ```{r pressure, echo=FALSE}
tree <- rpart(OJ.train$Purchase ~ . ,data = OJ.train, method = 'class')
#summary(tree)

pred = predict(tree,newdata = OJ.test,type = c("class"))

print(paste0("False Positive Rate: ", get_false_positive_rate(OJ.test$Purchase,pred)))

print(paste0("Error Rate: ", get_classification_error_rate(OJ.test$Purchase,pred)))

print(paste0("False Negative Rate: ", get_false_negative_rate(OJ.test$Purchase,pred)))

```


### Question 1.3
Using all the data (training and test put together), use the bagging approach to do the same analysis again and compare the results of the different error rates.
```{r}
set.seed(1)
n_pred <- ncol(OJ.train) - 1

bag.OJ <- randomForest(OJ.train$Purchase ~ .,
                           data = OJ.train,
                           mtry=n_pred, 
                           importance=TRUE)

bag.pred = predict(bag.OJ,newdata = OJ.test,type = c("class"))

print(paste0("False Positive Rate: ", get_false_positive_rate(OJ.test$Purchase,bag.pred)))

print(paste0("Error Rate: ", get_classification_error_rate(OJ.test$Purchase,bag.pred)))

print(paste0("False Negative Rate: ", get_false_negative_rate(OJ.test$Purchase,bag.pred)))

```

### Question 1.4
Using all the data (training and test put together), use the random forest approach to redo the same analysis and compare the results of the different error rates.
```{r}
set.seed(1)

rf.OJ <- randomForest(OJ.train$Purchase ~ .,
                           data = OJ.train,
                           #mtry=n_pred, 
                           importance=TRUE)

rf.pred = predict(rf.OJ,newdata = OJ.test,type = c("class"))

print(paste0("False Positive Rate: ", get_false_positive_rate(OJ.test$Purchase,rf.pred)))

print(paste0("Error Rate: ", get_classification_error_rate(OJ.test$Purchase,rf.pred)))

print(paste0("False Negative Rate: ", get_false_negative_rate(OJ.test$Purchase,rf.pred)))

```

### Question 1.5
Calculate the importance of the variables in the classification tree constructed in 2) and the forest constructed in 4). Compare.
```{r}
set.seed(1)

as.data.frame(importance(rf.OJ))
varImpPlot(rf.OJ)
```

```{r}
set.seed(1)

as.data.frame(tree$variable.importance)
#varImpPlot(tree)
```

### Question 1.6
Using all the data (training and test put together), use the boosting approach to do the same analysis again and compare the results of the error rates between all tested methods.
```{r}
set.seed(1)

boost.OJ = boosting(factor(OJ.train$Purchase) ~ ., 
                    data=OJ.train, 
                    #mfinal = 100, 
                    coeflearn = 'Freund') 
                    #control=rpart.control(maxdepth=10))
boost.OJ$importance
```